{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMMYbEEXs5NNuTlnh3F64PK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# 1. ì½”ë© í™˜ê²½ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","# gymnasium (RL í™˜ê²½), pygame (ë Œë”ë§ ì—”ì§„), moviepy (ë¹„ë””ì˜¤ ì €ì¥)\n","!pip install gymnasium pygame moviepy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRyKNnFMsJ_C","executionInfo":{"status":"ok","timestamp":1765098020517,"user_tz":-540,"elapsed":13902,"user":{"displayName":"Rai-kyong Jeong","userId":"10124706338105457970"}},"outputId":"6790930f-7e33-4dbf-fcc7-4a98ee074ecc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n","Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (2.6.1)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.2)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.11.12)\n"]}]},{"cell_type":"code","source":["import gymnasium as gym\n","from gymnasium import spaces\n","import numpy as np\n","import pygame\n","import random\n","import os\n","import glob\n","import io\n","import base64\n","import datetime\n","from collections import deque\n","from IPython.display import HTML, display\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, optimizers, losses\n","from google.colab import drive\n","import shutil\n","\n","# =========================================================\n","# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ (ì €ì¥ì†Œ ì—°ê²°)\n","# =========================================================\n","drive.mount('/content/drive')\n","GDRIVE_BASE_PATH = '/content/drive/MyDrive/Colab Notebooks/reinforcement learning/Final_Model_4to8'\n","\n","# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤. (ì—ëŸ¬ ë°©ì§€)\n","if not os.path.exists(GDRIVE_BASE_PATH):\n","    os.makedirs(GDRIVE_BASE_PATH)\n","\n","# =========================================================\n","# 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜\n","# =========================================================\n","\n","def show_video(video_path, video_width=600):\n","    \"\"\"\n","    [ë¹„ë””ì˜¤ ì¬ìƒê¸°]\n","    ì €ì¥ëœ mp4 íŒŒì¼ì„ ì½ì–´ì„œ ì½”ë© í™”ë©´ì— í”Œë ˆì´ì–´ë¡œ ë„ì›Œì¤ë‹ˆë‹¤.\n","    \"\"\"\n","    if not os.path.exists(video_path): return\n","    video_file = open(video_path, \"rb\").read()\n","    # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ì›¹ ë¸Œë¼ìš°ì €ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ë¬¸ìì—´(base64)ë¡œ ë³€í™˜\n","    video_url = f\"data:video/mp4;base64,{base64.b64encode(video_file).decode()}\"\n","    # HTML íƒœê·¸ë¥¼ ì´ìš©í•´ í™”ë©´ì— ì¶œë ¥\n","    display(HTML(f\"\"\"<video width=\"{video_width}\" controls autoplay loop><source src=\"{video_url}\"></video>\"\"\"))\n","\n","def get_success_threshold(grid_size):\n","    \"\"\"\n","    [í•©ê²© ì»¤íŠ¸ë¼ì¸ ê³„ì‚°]\n","    ëª©í‘œ ì ìˆ˜ = ì­íŒŸ ë³´ë„ˆìŠ¤(500) + ì „ì²´ íƒ€ì¼ ìˆ˜(ì¹¸ë‹¹ 1ì  ë³´ë„ˆìŠ¤ ê°ì•ˆ)\n","    ì´ ì ìˆ˜ë¥¼ ë„˜ì–´ì•¼ 'ì™„ë²½í•˜ê²Œ í´ë¦¬ì–´í–ˆë‹¤'ê³  íŒë‹¨í•©ë‹ˆë‹¤.\n","    \"\"\"\n","    total_cells = grid_size * grid_size\n","    return 500.0 + float(total_cells)\n","\n","def evaluate_and_record(agent, max_grid_size, current_grid_size, episode_num, run_id):\n","    \"\"\"\n","    [ì‹œê°ì  í‰ê°€ - CCTV ë…¹í™”]\n","    í˜„ì¬ ì—ì´ì „íŠ¸ì˜ ì‹¤ë ¥ì„ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ê¸° ìœ„í•´ í•œ íŒì„ ë…¹í™”í•©ë‹ˆë‹¤.\n","    \"\"\"\n","    video_dir = f\"./videos/{run_id}/eval_{episode_num}\"\n","\n","    # í‰ê°€ìš© í™˜ê²½ ìƒì„± (rgb_array ëª¨ë“œëŠ” í™”ë©´ì„ ì´ë¯¸ì§€ë¡œ ë±‰ì–´ëƒ„ -> ë…¹í™” ê°€ëŠ¥)\n","    eval_env = ZipGeneralEnv(\n","        max_grid_size=max_grid_size,\n","        min_grid_size=current_grid_size,\n","        target_grid_size=current_grid_size,\n","        render_mode=\"rgb_array\"\n","    )\n","    # ë‚œì´ë„ë¥¼ ê³ ì •í•©ë‹ˆë‹¤ (ì˜ˆ: 5x5ë©´ 5x5ë§Œ ë‚˜ì˜¤ê²Œ)\n","    eval_env.set_curriculum_level(current_grid_size)\n","\n","    # Gymì˜ ë…¹í™” ê¸°ëŠ¥(Wrapper)ì„ í™˜ê²½ì— ì”Œì›ë‹ˆë‹¤.\n","    env_to_record = gym.wrappers.RecordVideo(eval_env, video_dir, episode_trigger=lambda e: e == 0)\n","\n","    # ê²Œì„ ì‹œì‘!\n","    obs, info = env_to_record.reset()\n","    valid_actions = info['valid_actions'] # ì²« ë²ˆì§¸ ìœ íš¨ í–‰ë™ ìˆ˜ì‹ \n","    done = False; total_reward = 0\n","\n","    # í‰ê°€ ì¤‘ì—ëŠ” íƒí—˜(ëœë¤ í–‰ë™)ì„ ë•ë‹ˆë‹¤.\n","    orig_eps = agent.epsilon\n","    agent.epsilon = 0.0\n","\n","    while not done:\n","        # ì—ì´ì „íŠ¸ê°€ í–‰ë™ ê²°ì •\n","        action = agent.act(obs, valid_actions)\n","\n","        # í–‰ë™ ì‹¤í–‰\n","        obs, reward, terminated, truncated, info = env_to_record.step(action)\n","\n","        # [ì¤‘ìš”] ë°”ë€ ìƒí™©ì—ì„œì˜ ìœ íš¨ í–‰ë™ ì—…ë°ì´íŠ¸\n","        valid_actions = info['valid_actions']\n","\n","        done = terminated or truncated\n","        total_reward += reward\n","\n","    # ë…¹í™” ì¢…ë£Œ ë° ìì› í•´ì œ\n","    env_to_record.close()\n","\n","    # íƒí—˜ë¥ ì„ ì›ë˜ëŒ€ë¡œ ëŒë ¤ë†“ìŠµë‹ˆë‹¤ (í›ˆë ¨ ì¬ê°œë¥¼ ìœ„í•´)\n","    agent.epsilon = orig_eps\n","\n","    print(f\"   >>> ğŸ¥ [Video Rec] Size:{current_grid_size}x{current_grid_size} | Score:{total_reward:.1f}\")\n","\n","    # ì €ì¥ëœ ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ì•„ì„œ í™”ë©´ì— ë³´ì—¬ì£¼ê¸°\n","    video_files = glob.glob(f\"{video_dir}/*.mp4\")\n","    if video_files:\n","        latest = max(video_files, key=os.path.getmtime) # ê°€ì¥ ìµœê·¼ íŒŒì¼\n","        show_video(latest, video_width=300)\n","\n","    return total_reward\n","\n","def run_comprehensive_exam(agent, eval_env_instance, size_list, episodes_per_size=10):\n","    \"\"\"\n","    [ì¢…í•© ì¡¸ì—… ì‹œí—˜]\n","    ì£¼ì–´ì§„ ì‚¬ì´ì¦ˆ ëª©ë¡(ì˜ˆ: 4, 6, 8)ì— ëŒ€í•´ ê°ê° 10ë²ˆì”© ì‹œí—˜ì„ ë´…ë‹ˆë‹¤.\n","    ëª¨ë“  ì‚¬ì´ì¦ˆì—ì„œ í‰ê·  90% ì´ìƒì˜ ìŠ¹ë¥ ì„ ë³´ì—¬ì•¼ 'ì¡¸ì—…'ì…ë‹ˆë‹¤.\n","    \"\"\"\n","    print(f\"\\n   ğŸ‘® [ì¢…í•© ì¡¸ì—… ì‹œí—˜] ë²”ìœ„ {size_list} ê²€ì¦ ì‹œì‘ (ê° {episodes_per_size}íŒ)...\")\n","\n","    orig_eps = agent.epsilon\n","    agent.epsilon = 0.0 # ì»¤ë‹ ê¸ˆì§€ (ìˆœìˆ˜ ì‹¤ë ¥)\n","\n","    results = {}\n","    all_passed = True # ì¼ë‹¨ í•©ê²©ì´ë¼ê³  ê°€ì •í•˜ê³  ê²€ì¦ ì‹œì‘\n","\n","    for size in size_list:\n","        # ì‹œí—˜ í™˜ê²½ ë‚œì´ë„ ì„¤ì •\n","        eval_env_instance.set_curriculum_level(size)\n","        target_score = get_success_threshold(size) # í•©ê²© ê¸°ì¤€ ì ìˆ˜\n","        success_count = 0\n","\n","        # ì •í•´ì§„ íšŸìˆ˜ë§Œí¼ ë°˜ë³µ ì‹œí—˜\n","        for _ in range(episodes_per_size):\n","            obs, info = eval_env_instance.reset()\n","            valid_actions = info['valid_actions']\n","            done = False; total_reward = 0\n","\n","            while not done:\n","                action = agent.act(obs, valid_actions)\n","                obs, reward, terminated, truncated, info = eval_env_instance.step(action)\n","                valid_actions = info['valid_actions']\n","                done = terminated or truncated\n","                total_reward += reward\n","\n","            # ê¸°ì¤€ ì ìˆ˜ ë„˜ìœ¼ë©´ ì„±ê³µ ì¹´ìš´íŠ¸\n","            if total_reward >= target_score:\n","                success_count += 1\n","\n","        # ì„±ê³µë¥  ê³„ì‚°\n","        pass_rate = (success_count / episodes_per_size) * 100\n","        results[size] = pass_rate\n","        print(f\"      - {size}x{size}: ì„±ê³µë¥  {pass_rate:.0f}%\")\n","\n","        # 90ì  ë¯¸ë§Œì¸ ê³¼ëª©ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì¡¸ì—… ì‹¤íŒ¨\n","        if pass_rate < 90.0:\n","            all_passed = False\n","\n","    # ì‹œí—˜ ëë‚¬ìœ¼ë‹ˆ ì›ë˜ëŒ€ë¡œ ë³µêµ¬\n","    agent.epsilon = orig_eps\n","    return all_passed, results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvytfM3_lyPL","executionInfo":{"status":"ok","timestamp":1765098199763,"user_tz":-540,"elapsed":21820,"user":{"displayName":"Rai-kyong Jeong","userId":"10124706338105457970"}},"outputId":"62739443-fb79-4bac-c3ab-d83a8dbca306"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import gymnasium as gym\n","from gymnasium import spaces\n","import numpy as np\n","import pygame\n","import random\n","import os\n","from collections import deque # BFS íƒìƒ‰ì„ ìœ„í•œ íš¨ìœ¨ì ì¸ í(Queue)\n","\n","class ZipGeneralEnv(gym.Env):\n","    \"\"\"\n","    [Zip ê²Œì„ ê°•í™”í•™ìŠµ í™˜ê²½ - Dual View & Dead-end ê°ì§€ ìµœì¢…íŒ]\n","\n","    ì´ í™˜ê²½ì€ ì—ì´ì „íŠ¸ì—ê²Œ ë‘ ê°€ì§€ ì‹œê° ì •ë³´ì™€ ê°•ë ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n","\n","    1. ì‹œê° ì •ë³´ (Dual Eyes):\n","       - Local View (7x7): ë‚´ ì£¼ë³€ì˜ ë¯¸ì„¸í•œ ì¥ì• ë¬¼ì„ í”¼í•˜ê¸° ìœ„í•¨ (ì „ìˆ )\n","       - Global View (12x12): ë§µ ì „ì²´ì˜ ì—°ê²° ìƒíƒœì™€ ê³ ë¦½ì„ íŒŒì•…í•˜ê¸° ìœ„í•¨ (ì „ëµ)\n","\n","    2. í•µì‹¬ ë¡œì§ (Dead-end Detection):\n","       - BFS ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ì´ë™í•  ë•Œë§ˆë‹¤ ë¯¸ë˜ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.\n","       - 'ë” ì´ìƒ ê¹° ìˆ˜ ì—†ëŠ” ìƒíƒœ'ê°€ ê°ì§€ë˜ë©´ ì¦‰ì‹œ ê²Œì„ì„ ì¢…ë£Œ(Kill)í•˜ê³  í° ë²Œì ì„ ì¤ë‹ˆë‹¤.\n","    \"\"\"\n","    metadata = {'render_modes': ['human', 'rgb_array'], 'render_fps': 10}\n","\n","    def __init__(self, max_grid_size=12, min_grid_size=4, target_grid_size=8, render_mode=None):\n","        super().__init__()\n","\n","        # ---------------------------------------------------------\n","        # 1. í™˜ê²½ ê¸°ë³¸ ì„¤ì •\n","        # ---------------------------------------------------------\n","        self.max_grid_size = max_grid_size   # ë©”ëª¨ë¦¬ í• ë‹¹ìš© ìµœëŒ€ í¬ê¸°\n","        self.min_grid_size = min_grid_size   # ì‹œì‘ ë‚œì´ë„\n","        self.target_grid_size = target_grid_size\n","        self.render_mode = render_mode\n","        self.grid_size = min_grid_size\n","\n","        self.cell_size = 40\n","        self.window_size = self.max_grid_size * self.cell_size\n","        self.screen = None; self.clock = None; self.font = None\n","\n","        # ---------------------------------------------------------\n","        # 2. ì‹œì•¼ ì„¤ì • (Local Viewìš©)\n","        # ---------------------------------------------------------\n","        self.view_range = 7\n","        self.view_pad = self.view_range // 2\n","\n","        # ---------------------------------------------------------\n","        # 3. ë°ì´í„° ê·œê²© (Observation Space) - [ìˆ˜ì •ë¨: 3ê°œ ì…ë ¥]\n","        # ---------------------------------------------------------\n","        self.observation_space = spaces.Dict({\n","            # (A) Local: ë‚´ ì£¼ë³€ 7x7 (ë¯¸ì„¸ ì»¨íŠ¸ë¡¤ìš©)\n","            \"local\": spaces.Box(low=0, high=self.max_grid_size**2,\n","                               shape=(self.view_range, self.view_range, 4), dtype=np.float32),\n","\n","            # (B) Global: ë§µ ì „ì²´ 12x12 (ì „ì²´ ì „ëµìš©) - ë§µì´ ì‘ìœ¼ë©´ ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ íŒ¨ë”©ë¨\n","            \"global\": spaces.Box(low=0, high=self.max_grid_size**2,\n","                               shape=(self.max_grid_size, self.max_grid_size, 4), dtype=np.float32),\n","\n","            # (C) Vector: ë°©í–¥ ë° ìƒíƒœ ìˆ˜ì¹˜ ì •ë³´\n","            \"vector\": spaces.Box(low=-1.0, high=1.0, shape=(9,), dtype=np.float32)\n","        })\n","\n","        self.action_space = spaces.Discrete(4) # ìƒ, í•˜, ì¢Œ, ìš°\n","        self.nodes = {} # ìˆ«ì ë…¸ë“œ ìœ„ì¹˜\n","\n","        # ë‚œì´ë„ ë¶„í¬ (Main Loopì—ì„œ ì œì–´)\n","        self.size_distribution = {4: 1.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0}\n","\n","        # 4. Pygame ì´ˆê¸°í™”\n","        if self.render_mode == 'rgb_array':\n","            os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n","        if self.render_mode in ['human', 'rgb_array']:\n","            self._init_pygame()\n","\n","    def _init_pygame(self):\n","        \"\"\"í™”ë©´ ê·¸ë¦¬ê¸° ë„êµ¬ ì¤€ë¹„\"\"\"\n","        pygame.init()\n","        self.screen = pygame.Surface((self.window_size, self.window_size))\n","        self.clock = pygame.time.Clock()\n","        self.font = pygame.font.Font(None, 24)\n","        if self.render_mode == 'human':\n","            pygame.display.set_caption(\"Zip General (Dual View)\")\n","            self.screen = pygame.display.set_mode((self.window_size, self.window_size))\n","\n","    def set_curriculum_level(self, new_size):\n","        \"\"\"í‰ê°€ìš©: íŠ¹ì • ë‚œì´ë„ë§Œ 100% ë‚˜ì˜¤ê²Œ ê³ ì •\"\"\"\n","        if new_size <= self.max_grid_size:\n","            self.grid_size = new_size\n","            self.min_grid_size = new_size\n","            self.target_grid_size = new_size\n","            self.max_episode_steps = self.grid_size * self.grid_size * 3\n","            self.total_cells = self.grid_size * self.grid_size\n","            self.size_distribution = {s: (1.0 if s == new_size else 0.0) for s in range(4, 9)}\n","\n","    def reset(self, seed=None, options=None):\n","        \"\"\"[ìƒˆ ê²Œì„] ë§µì„ ìƒì„±í•˜ê³  ì´ˆê¸°í™”\"\"\"\n","        super().reset(seed=seed)\n","\n","        # 1. í™•ë¥  ë¶„í¬ì— ë”°ë¼ ë§µ í¬ê¸° ê²°ì •\n","        sizes = list(self.size_distribution.keys())\n","        weights = list(self.size_distribution.values())\n","        if sum(weights) > 0:\n","            self.grid_size = random.choices(sizes, weights=weights, k=1)[0]\n","        else:\n","            self.grid_size = self.min_grid_size\n","\n","        self.max_episode_steps = self.grid_size * self.grid_size * 3\n","        self.total_cells = self.grid_size * self.grid_size\n","\n","        # 2. ë§µ ìƒì„± (ì •ë‹µ ê²½ë¡œ í¬í•¨)\n","        min_nodes = 3\n","        max_nodes = min(self.grid_size + 2, 20)\n","        self.num_nodes = random.randint(min_nodes, max_nodes)\n","        self._generate_solvable_map()\n","\n","        # 3. ìƒíƒœ ì´ˆê¸°í™”\n","        self.current_target = 2\n","        self.path_drawn = set()\n","        self.path_drawn.add(self.pen_pos)\n","        self.current_step = 0\n","\n","        if self.render_mode == 'human': self._render_frame()\n","        return self._get_observation(), self._get_info()\n","\n","    # â­ï¸ [í•µì‹¬ ì•Œê³ ë¦¬ì¦˜] ê²½ë¡œ ì†Œë©¸ ê°ì§€ (BFS)\n","    # ì—­í• : \"ë§Œì•½ ë‚´ê°€ ê±°ê¸°ë¡œ ê°€ë©´(Simulate), ê²Œì„ì„ ê¹° ìˆ˜ ìˆëŠ”ê°€?\"ë¥¼ íŒë‹¨\n","    def _is_dead_end(self, next_pos, visited_set):\n","        # 1. ê°€ìƒ ë°©ë¬¸ ì²˜ë¦¬ (ì‹œë®¬ë ˆì´ì…˜)\n","        temp_visited = visited_set.copy()\n","        temp_visited.add(next_pos)\n","\n","        target_pos = self.nodes.get(self.current_target)\n","\n","        # 2. ë‚¨ì€ ë¹ˆì¹¸ ê°œìˆ˜ í™•ì¸\n","        # (ë„ë‹¬í•´ì•¼ í•  ì´ ì¹¸ ìˆ˜)\n","        total_remaining_cells = 0\n","        for r in range(self.grid_size):\n","            for c in range(self.grid_size):\n","                if (r, c) not in temp_visited:\n","                    total_remaining_cells += 1\n","\n","        # ë¹ˆì¹¸ì´ 0ê°œë©´ ì„±ê³µ ì§ì „ì´ë¯€ë¡œ Dead End ì•„ë‹˜\n","        if total_remaining_cells == 0: return False\n","\n","        # 3. [ê²€ì¦ 1] ëª©í‘œ ë„ë‹¬ ê°€ëŠ¥ì„± í™•ì¸\n","        # ê·œì¹™: \"ì§€ê¸ˆ ë‹¹ì¥ ëª©í‘œ ìˆ«ìê¹Œì§€ ê°€ëŠ” ê¸¸ì´ ëš«ë ¤ìˆëŠ”ê°€?\"\n","        # ì£¼ì˜: ë¯¸ë˜ì˜ ìˆ«ì ë…¸ë“œ(ë‹¤ìŒ ëª©í‘œë“¤)ëŠ” í˜„ì¬ 'ë²½'ìœ¼ë¡œ ì·¨ê¸‰ë¨\n","        queue = deque([next_pos])\n","        bfs_visited = temp_visited.copy()\n","        target_found = False\n","\n","        while queue:\n","            r, c = queue.popleft()\n","            if (r, c) == target_pos:\n","                target_found = True; break\n","\n","            for dr, dc in [(-1,0), (1,0), (0,-1), (0,1)]:\n","                nr, nc = r + dr, c + dc\n","                if (0 <= nr < self.grid_size and 0 <= nc < self.grid_size):\n","                    if (nr, nc) not in bfs_visited:\n","                        # ìˆ«ì ë…¸ë“œëŠ” ìˆœì„œê°€ ì•„ë‹ˆë©´ í†µê³¼ ë¶ˆê°€ (ë²½)\n","                        if (nr, nc) in self.nodes.values() and (nr, nc) != target_pos:\n","                            continue\n","                        bfs_visited.add((nr, nc))\n","                        queue.append((nr, nc))\n","\n","        # ëª©í‘œ ìì²´ê°€ ë§‰í˜”ìœ¼ë©´ -> ì‚¬ë§\n","        if not target_found and target_pos is not None: return True\n","\n","        # 4. [ê²€ì¦ 2] ì „ì²´ ì—°ê²°ì„± í™•ì¸ (ê³ ë¦½ ê°ì§€)\n","        # ê·œì¹™: \"ë¯¸ë˜ì— ëª¨ë“  ìˆ«ìê°€ ì—´ë¦°ë‹¤ê³  ê°€ì •í–ˆì„ ë•Œ, ëª» ê°€ëŠ” ë¹ˆì¹¸ì´ ìƒê¸°ëŠ”ê°€?\"\n","\n","        # ë‚¨ì€ ë¹ˆì¹¸ ì¤‘ ì•„ë¬´ê±°ë‚˜ í•˜ë‚˜ ì¡ì•„ì„œ ì‹œì‘ì ìœ¼ë¡œ ì„¤ì •\n","        start_node = None\n","        for r in range(self.grid_size):\n","            for c in range(self.grid_size):\n","                if (r, c) not in temp_visited:\n","                    start_node = (r, c); break\n","            if start_node: break\n","\n","        if not start_node: return False # ë¹ˆì¹¸ ì—†ìŒ\n","\n","        # ì™„í™”ëœ BFS (ìˆ«ì ë…¸ë“œ í†µê³¼ ê°€ëŠ¥)\n","        queue = deque([start_node])\n","        bfs_visited_relaxed = temp_visited.copy()\n","        reachable_count = 0\n","\n","        while queue:\n","            r, c = queue.popleft()\n","            reachable_count += 1\n","\n","            for dr, dc in [(-1,0), (1,0), (0,-1), (0,1)]:\n","                nr, nc = r + dr, c + dc\n","                if (0 <= nr < self.grid_size and 0 <= nc < self.grid_size):\n","                    if (nr, nc) not in bfs_visited_relaxed:\n","                        bfs_visited_relaxed.add((nr, nc))\n","                        queue.append((nr, nc))\n","\n","        # ë‚´ê°€ ê°ˆ ìˆ˜ ìˆëŠ” ì¹¸ < ì „ì²´ ë‚¨ì€ ì¹¸ -> ì–´ë”˜ê°€ ê³ ë¦½ë¨ -> ì‚¬ë§\n","        if reachable_count < total_remaining_cells: return True\n","\n","        return False # ë‘ ê²€ì¦ í†µê³¼ ì‹œ ì•ˆì „\n","\n","    def step(self, action):\n","        self.current_step += 1\n","        (r, c) = self.pen_pos\n","\n","        # 1. ì´ë™ ì¢Œí‘œ ê³„ì‚°\n","        if action == 0: new_pos = (r - 1, c)\n","        elif action == 1: new_pos = (r + 1, c)\n","        elif action == 2: new_pos = (r, c - 1)\n","        elif action == 3: new_pos = (r, c + 1)\n","\n","        # ë§µ ë°– ì²˜ë¦¬\n","        if not (0 <= new_pos[0] < self.grid_size and 0 <= new_pos[1] < self.grid_size):\n","            new_pos = self.pen_pos\n","\n","        self.pen_pos = new_pos\n","        is_new_tile = new_pos not in self.path_drawn\n","\n","        reward = 0.0; terminated = False; truncated = False\n","        reward -= 0.1 # ì‹œê°„ ë¹„ìš©\n","\n","        if is_new_tile:\n","            # â­ï¸ [í•µì‹¬] ì¡°ê¸° ì¢…ë£Œ ë° ê°•ë ¥í•œ ë²Œì \n","            if self._is_dead_end(new_pos, self.path_drawn):\n","                # ë²Œì : ë‚¨ì€ ë¹ˆì¹¸ ê°œìˆ˜ë§Œí¼ ì¶”ê°€ ë²Œì  ë¶€ì—¬ (ì´ˆë°˜ ì‹¤ìˆ˜ì¼ìˆ˜ë¡ ë” í¬ê²Œ í˜¼ë‚¨)\n","                visited_count = len(self.path_drawn) + 1\n","                remaining_cells = self.valid_cells_count - visited_count\n","                penalty = 50.0 + float(remaining_cells)\n","\n","                reward -= penalty\n","                terminated = True # ì¦‰ì‹œ ê²Œì„ ì˜¤ë²„\n","\n","                # ë§ˆì§€ë§‰ ìœ„ì¹˜ ë°˜ì˜\n","                self.pen_pos = new_pos\n","                self.path_drawn.add(new_pos)\n","                return self._get_observation(), reward, terminated, truncated, self._get_info()\n","            else:\n","                reward += 2.0 # ìƒì¡´ ë³´ìƒ\n","\n","            self.pen_pos = new_pos\n","            self.path_drawn.add(new_pos)\n","        else:\n","            self.pen_pos = new_pos\n","\n","        # 2. ëª©í‘œ ë„ë‹¬ ì²´í¬\n","        current_target_pos = self.nodes.get(self.current_target)\n","        if self.pen_pos == current_target_pos:\n","            if self.current_target == self.actual_num_nodes:\n","                # ìµœì¢… ì™„ë£Œ\n","                missed = self.valid_cells_count - len(self.path_drawn)\n","                if missed == 0:\n","                    reward += 500.0; terminated = True # ì­íŒŸ\n","                else:\n","                    # (ì´ë¡ ìƒ ë„ë‹¬ ëª»í•˜ì§€ë§Œ ì•ˆì „ì¥ì¹˜)\n","                    clear_bonus = 200.0 - (float(missed) * 5.0)\n","                    reward += max(0.0, clear_bonus); terminated = True\n","            else:\n","                # ì¤‘ê°„ ëª©í‘œ\n","                reward += 10.0; self.current_target += 1\n","\n","        # 3. ê°‡í˜ ì²´í¬ (BFS ë•ë¶„ì— ê±°ì˜ ë°œìƒ ì•ˆ í•¨)\n","        info = self._get_info()\n","        if not terminated and info['is_stuck']:\n","            terminated = True\n","            missed = self.valid_cells_count - len(self.path_drawn)\n","            reward -= (50.0 + float(missed))\n","\n","        # 4. ì‹œê°„ ì´ˆê³¼\n","        if self.current_step >= self.max_episode_steps: truncated = True\n","\n","        return self._get_observation(), reward, terminated, truncated, info\n","\n","    def _get_observation(self):\n","        \"\"\"\n","        [AIì˜ ëˆˆ - Dual View ìƒì„±]\n","        1. Local View (7x7): ë¯¸ì„¸ ì»¨íŠ¸ë¡¤ìš©\n","        2. Global View (12x12): ì „ì—­ ì „ëµìš©\n","        \"\"\"\n","        shape = (self.max_grid_size, self.max_grid_size)\n","\n","        # 4ê°œ ì±„ë„ ì •ë³´ ìƒì„±\n","        node_board = np.zeros(shape, dtype=np.float32)\n","        path_board = np.zeros(shape, dtype=np.float32)\n","        pen_pos_board = np.zeros(shape, dtype=np.float32)\n","        target_board = np.zeros(shape, dtype=np.float32)\n","\n","        for num, (r, c) in self.nodes.items(): node_board[r, c] = num\n","        for (r, c) in self.path_drawn: path_board[r, c] = 1.0\n","        pen_pos_board[self.pen_pos] = 1.0\n","        t_pos = self.nodes.get(self.current_target, (-1, -1))\n","        if t_pos != (-1, -1): target_board[t_pos[0], t_pos[1]] = 1.0\n","\n","        # â­ï¸ [Global View] ì „ì²´ ë§µ ìŠ¤íƒ\n","        global_grid_obs = np.stack([\n","            node_board, path_board, pen_pos_board, target_board\n","        ], axis=-1)\n","\n","        # â­ï¸ [Local View] 7x7 í¬ë¡­ & íŒ¨ë”©\n","        pad = self.view_pad\n","        padded_node = np.pad(node_board, pad, constant_values=-1)\n","        padded_path = np.pad(path_board, pad, constant_values=1)\n","        padded_pen = np.pad(pen_pos_board, pad, constant_values=0)\n","        padded_target = np.pad(target_board, pad, constant_values=0)\n","\n","        pr, pc = self.pen_pos[0] + pad, self.pen_pos[1] + pad\n","        slice_r = slice(pr - pad, pr + pad + 1)\n","        slice_c = slice(pc - pad, pc + pad + 1)\n","\n","        local_grid_obs = np.stack([\n","            padded_node[slice_r, slice_c], padded_path[slice_r, slice_c],\n","            padded_pen[slice_r, slice_c], padded_target[slice_r, slice_c]\n","        ], axis=-1)\n","\n","        # [Vector] ìˆ˜ì¹˜ ì •ë³´\n","        norm = float(self.max_grid_size)\n","        scale_ratio = self.grid_size / self.max_grid_size\n","        cy, cx = self.pen_pos\n","        if t_pos != (-1, -1):\n","            ty, tx = t_pos\n","            dy, dx = (ty - cy) / norm, (tx - cx) / norm\n","        else: dy, dx = 0, 0\n","        progress_ratio = (self.current_target - 1) / max(self.actual_num_nodes, 1)\n","        fill_ratio = len(self.path_drawn) / self.total_cells\n","        valid = self._get_valid_actions()\n","        surround_info = [1.0 if not v else 0.0 for v in valid]\n","\n","        vector_obs = np.array([dy, dx, progress_ratio, fill_ratio, scale_ratio, *surround_info], dtype=np.float32)\n","\n","        # 3ê°œì˜ ì…ë ¥ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜\n","        return {\"local\": local_grid_obs, \"global\": global_grid_obs, \"vector\": vector_obs}\n","\n","    def _get_info(self):\n","        valid = self._get_valid_actions()\n","        return {'valid_actions': valid, 'is_stuck': not np.any(valid)}\n","\n","    def _get_valid_actions(self):\n","        (r, c) = self.pen_pos\n","        moves = [(r - 1, c), (r + 1, c), (r, c - 1), (r, c + 1)]\n","        valid = np.zeros(4, dtype=bool)\n","        t_pos = self.nodes.get(self.current_target)\n","        for i, (nr, nc) in enumerate(moves):\n","            if not (0 <= nr < self.grid_size and 0 <= nc < self.grid_size): continue\n","            if (nr, nc) in self.path_drawn: continue\n","            if (nr, nc) in self.nodes.values():\n","                if (nr, nc) == t_pos: valid[i] = True\n","            else: valid[i] = True\n","        return valid\n","\n","    def render(self):\n","        if self.render_mode == 'rgb_array': return self._render_frame()\n","        elif self.render_mode == 'human':\n","            self._render_frame()\n","            pygame.display.flip()\n","            self.clock.tick(self.metadata[\"render_fps\"])\n","\n","    def _render_frame(self):\n","        if self.screen is None: return\n","        self.screen.fill((255, 255, 255))\n","        for (r, c) in self.path_drawn:\n","            pygame.draw.rect(self.screen, (220, 220, 220), (c*self.cell_size, r*self.cell_size, self.cell_size, self.cell_size))\n","        for num, (r, c) in self.nodes.items():\n","            center = (c*self.cell_size + self.cell_size//2, r*self.cell_size + self.cell_size//2)\n","            color = (0, 150, 0) if num == self.current_target else (0, 0, 200)\n","            pygame.draw.circle(self.screen, color, center, self.cell_size//3)\n","            if self.font:\n","                text_surf = self.font.render(str(num), True, (255, 255, 255))\n","                text_rect = text_surf.get_rect(center=center)\n","                self.screen.blit(text_surf, text_rect)\n","        curr_center = (self.pen_pos[1]*self.cell_size + self.cell_size//2, self.pen_pos[0]*self.cell_size + self.cell_size//2)\n","        pygame.draw.circle(self.screen, (200, 0, 0), curr_center, self.cell_size//4)\n","        for i in range(self.grid_size + 1):\n","            pygame.draw.line(self.screen, (100,100,100), (0, i*self.cell_size), (self.grid_size*self.cell_size, i*self.cell_size))\n","            pygame.draw.line(self.screen, (100,100,100), (i*self.cell_size, 0), (i*self.cell_size, self.grid_size*self.cell_size))\n","        return np.transpose(pygame.surfarray.array3d(self.screen), (1, 0, 2))\n","\n","    def close(self):\n","        if self.screen is not None: pygame.display.quit(); pygame.quit(); self.screen = None\n","\n","    # --- ë§µ ìƒì„± ë¡œì§ (í•„ìˆ˜) ---\n","    def _generate_solvable_map(self):\n","        strategies = ['basic_snake', 'spiral', 'hybrid_vert', 'hybrid_horz']\n","        strategy = random.choice(strategies)\n","        if strategy == 'basic_snake': full_path = self._generate_snake_path()\n","        elif strategy == 'spiral': full_path = self._generate_spiral_path()\n","        elif strategy == 'hybrid_vert': full_path = self._generate_hybrid_path(mode='vert_first')\n","        else: full_path = self._generate_hybrid_path(mode='horz_first')\n","        self.valid_cells_count = len(full_path)\n","        path_indices = [0]\n","        available_indices = range(1, len(full_path) - 1)\n","        needed_middle = self.num_nodes - 2\n","        safe_k = min(len(available_indices), needed_middle)\n","        if safe_k > 0:\n","            middle_indices = sorted(random.sample(available_indices, safe_k))\n","            path_indices.extend(middle_indices)\n","        path_indices.append(len(full_path) - 1)\n","        self.nodes = {}\n","        for i, idx in enumerate(path_indices):\n","            self.nodes[i + 1] = full_path[idx]\n","        self.actual_num_nodes = len(self.nodes)\n","        self.pen_pos = self.nodes[1]\n","\n","    def _generate_hybrid_path(self, mode='vert_first'):\n","        path = []\n","        if mode == 'vert_first':\n","            if self.grid_size < 4: return self._generate_snake_path()\n","            split_col = random.randint(1, self.grid_size - 2)\n","            for c in range(split_col + 1):\n","                col_cells = [(r, c) for r in range(self.grid_size)]\n","                if c % 2 == 1: col_cells.reverse()\n","                path.extend(col_cells)\n","            last_r, last_c = path[-1]\n","            remaining_cols = list(range(split_col + 1, self.grid_size))\n","            if last_r == self.grid_size - 1: rows = list(range(self.grid_size - 1, -1, -1))\n","            else: rows = list(range(self.grid_size))\n","            for i, r in enumerate(rows):\n","                row_cells = [(r, c) for c in remaining_cols]\n","                if i % 2 == 1: row_cells.reverse()\n","                path.extend(row_cells)\n","        else:\n","            if self.grid_size < 4: return self._generate_snake_path()\n","            split_row = random.randint(1, self.grid_size - 2)\n","            for r in range(split_row + 1):\n","                row_cells = [(r, c) for c in range(self.grid_size)]\n","                if r % 2 == 1: row_cells.reverse()\n","                path.extend(row_cells)\n","            last_r, last_c = path[-1]\n","            remaining_rows = list(range(split_row + 1, self.grid_size))\n","            if last_c == self.grid_size - 1: cols = list(range(self.grid_size - 1, -1, -1))\n","            else: cols = list(range(self.grid_size))\n","            for i, c in enumerate(cols):\n","                col_cells = [(r, c) for r in remaining_rows]\n","                if i % 2 == 1: col_cells.reverse()\n","                path.extend(col_cells)\n","        return path\n","\n","    def _generate_spiral_path(self):\n","        path = []; r, c = 0, 0; dr, dc = 0, 1\n","        visited = np.zeros((self.grid_size, self.grid_size), dtype=bool)\n","        for _ in range(self.total_cells):\n","            path.append((r, c)); visited[r, c] = True\n","            nr, nc = r + dr, c + dc\n","            if not (0 <= nr < self.grid_size and 0 <= nc < self.grid_size) or visited[nr, nc]:\n","                dr, dc = dc, -dr; nr, nc = r + dr, c + dc\n","            if not (0 <= nr < self.grid_size and 0 <= nc < self.grid_size) or visited[nr, nc]: break\n","            r, c = nr, nc\n","        return path\n","\n","    def _generate_snake_path(self):\n","        path = []\n","        strategy = random.choice(['horz', 'vert', 'horz_rev', 'vert_rev'])\n","        if strategy == 'horz':\n","            for r in range(self.grid_size):\n","                row_cells = [(r, c) for c in range(self.grid_size)]\n","                if r % 2 == 1: row_cells.reverse()\n","                path.extend(row_cells)\n","        elif strategy == 'vert':\n","            for c in range(self.grid_size):\n","                col_cells = [(r, c) for r in range(self.grid_size)]\n","                if c % 2 == 1: col_cells.reverse()\n","                path.extend(col_cells)\n","        elif strategy == 'horz_rev':\n","            for r in range(self.grid_size - 1, -1, -1):\n","                row_cells = [(r, c) for c in range(self.grid_size)]\n","                if (self.grid_size - 1 - r) % 2 == 1: row_cells.reverse()\n","                path.extend(row_cells)\n","        elif strategy == 'vert_rev':\n","            for c in range(self.grid_size - 1, -1, -1):\n","                col_cells = [(r, c) for r in range(self.grid_size)]\n","                if (self.grid_size - 1 - c) % 2 == 1: col_cells.reverse()\n","                path.extend(col_cells)\n","        return path"],"metadata":{"id":"8UUyTdPnl78W","executionInfo":{"status":"ok","timestamp":1765098208213,"user_tz":-540,"elapsed":56,"user":{"displayName":"Rai-kyong Jeong","userId":"10124706338105457970"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ğŸ’¡ ì´ ì½”ë“œëŠ” Global Viewì™€ Local Viewë¥¼ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” 3-Stream êµ¬ì¡°ì…ë‹ˆë‹¤.\n","\n","# =========================================================\n","# 1. ì»¤ìŠ¤í…€ ë ˆì´ì–´ ì •ì˜ (Agent í´ë˜ìŠ¤ë³´ë‹¤ ë°˜ë“œì‹œ ë¨¼ì € ì •ì˜ë˜ì–´ì•¼ í•¨!)\n","# =========================================================\n","@tf.keras.utils.register_keras_serializable()\n","class DuelingMergeLayer(layers.Layer):\n","    \"\"\"\n","    [ë“€ì–¼ë§ ë³‘í•© ë ˆì´ì–´]\n","    ì—­í• : V(ìƒíƒœ ê°€ì¹˜)ì™€ A(í–‰ë™ ì´ë“)ë¥¼ í•©ì³ ìµœì¢… Qê°’ì„ ë§Œë“­ë‹ˆë‹¤.\n","    ì´ ìˆ˜ì‹ì´ ëª¨ë¸ì˜ ì•ˆì •ì„±ì„ í¬ê²Œ ë†’ì—¬ì¤ë‹ˆë‹¤.\n","    \"\"\"\n","    def __init__(self, **kwargs):\n","        super(DuelingMergeLayer, self).__init__(**kwargs)\n","\n","    def call(self, inputs):\n","        value, advantage = inputs\n","        # Q = V + (A - mean(A)) ê³µì‹ ì ìš©\n","        return value + (advantage - tf.reduce_mean(advantage, axis=1, keepdims=True))\n","\n","    def compute_output_shape(self, input_shape):\n","        # ì¶œë ¥ ëª¨ì–‘ì€ í–‰ë™ ê°œìˆ˜ë§Œí¼ì˜ Qê°’ ë²¡í„°ì…ë‹ˆë‹¤.\n","        return input_shape[1]\n","\n","    def get_config(self):\n","        return super(DuelingMergeLayer, self).get_config()\n","\n","# =========================================================\n","# 2. Dual View ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ì •ì˜\n","# =========================================================\n","class DualDQNAgent:\n","    \"\"\"\n","    [3-Stream ì•„í‚¤í…ì²˜]\n","    Local CNN (ì „ìˆ ) + Global CNN (ì „ëµ) + Vector MLP (ìƒí™© ì¸ì‹)\n","    \"\"\"\n","    def __init__(self, local_shape, global_shape, vector_shape, action_size):\n","        # ì…ë ¥ ì‰ì´í”„ 3ê°œ ì €ì¥ (Envì—ì„œ ë°›ì€ í¬ê¸°)\n","        self.local_shape = local_shape\n","        self.global_shape = global_shape\n","        self.vector_shape = vector_shape\n","        self.action_size = action_size\n","\n","        self.buffer = deque(maxlen=50000) # ê²½í—˜ ë¦¬í”Œë ˆì´ ë²„í¼\n","        self.gamma = 0.99 # í• ì¸ìœ¨ (ë¯¸ë˜ ë³´ìƒ ì¤‘ìš”ë„)\n","        self.epsilon = 1.0 # ì´ˆê¸° íƒí—˜ë¥ \n","        self.epsilon_min = 0.01\n","        self.learning_rate = 0.00025 # ì•ˆì •ì  í•™ìŠµì„ ìœ„í•œ ë‚®ì€ í•™ìŠµë¥ \n","\n","        # ë©”ì¸ ëª¨ë¸ê³¼ íƒ€ê²Ÿ ëª¨ë¸(Double DQN) ìƒì„±\n","        self.model = self._build_model()\n","        self.target_model = self._build_model()\n","        self.update_target_model()\n","\n","    def _build_model(self):\n","        \"\"\"ì‹ ê²½ë§ êµ¬ì¡° ì„¤ê³„ (3ê°œì˜ ë…ë¦½ì ì¸ ê²½ë¡œ)\"\"\"\n","\n","        # --- [1] Local View (7x7) ì²˜ë¦¬: ë¯¸ì„¸ ì»¨íŠ¸ë¡¤ ---\n","        # ë§µì´ ì»¤ì ¸ë„ ì´ ì‹œì•¼ëŠ” ë³€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ë²”ìš©ì„±ì˜ í•µì‹¬)\n","        input_local = layers.Input(shape=self.local_shape, name='local_input')\n","        x1 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_local)\n","        x1 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x1)\n","        x1 = layers.Flatten()(x1) # 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\n","\n","        # --- [2] Global View (12x12) ì²˜ë¦¬: ì „ì—­ ì „ëµ (Global Eyes) ---\n","        # ë§µ ì „ì²´ì˜ ì—°ê²°ì„±, í° íë¦„ì„ íŒŒì•…í•˜ì—¬ 'ê¸¸ ëŠì–´ë¨¹ëŠ” ì‹¤ìˆ˜'ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.\n","        input_global = layers.Input(shape=self.global_shape, name='global_input')\n","        x2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_global)\n","        x2 = layers.MaxPooling2D((2, 2))(x2) # í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ(Pooling) ì¶”ìƒí™” ë° ì¤‘ìš”í•œ íŒ¨í„´ë§Œ ì¶”ì¶œ\n","        x2 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x2)\n","        x2 = layers.Flatten()(x2) # 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\n","\n","        # --- [3] Vector Info ì²˜ë¦¬: ë‚˜ì¹¨ë°˜ ë° ìƒíƒœ ---\n","        # ë§µ í¬ê¸° ë¹„ìœ¨, ëª©í‘œê¹Œì§€ì˜ ë°©í–¥ ë“± ìˆ˜ì¹˜ ì •ë³´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n","        input_vector = layers.Input(shape=self.vector_shape, name='vector_input')\n","        y = layers.Dense(64, activation='relu')(input_vector)\n","\n","        # --- [4] í†µí•© (Merge) ---\n","        # ì„¸ ê°€ì§€ ì •ë³´ë¥¼ í•©ì³ì„œ ìµœì¢…ì ì¸ íŒë‹¨ ê·¼ê±°ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n","        combined = layers.Concatenate()([x1, x2, y])\n","        z = layers.Dense(256, activation='relu')(combined) # ì€ë‹‰ì¸µì˜ ìš©ëŸ‰ ì¦ê°€\n","\n","        # --- [5] Dueling Output (ìµœì¢… ê²°ì •) ---\n","        value = layers.Dense(1, activation='linear', name='value')(z) # V: ì´ ìƒíƒœì˜ ê°€ì¹˜\n","        advantage = layers.Dense(self.action_size, activation='linear', name='advantage')(z) # A: ê° í–‰ë™ì˜ ì´ë“\n","\n","        # DuelingMergeLayerë¥¼ ì‚¬ìš©í•´ ìµœì¢… Qê°’ì„ ê³„ì‚°\n","        output = DuelingMergeLayer(name='q_values')([value, advantage])\n","\n","        # ëª¨ë¸ ì¡°ë¦½ ë° ì»´íŒŒì¼\n","        model = models.Model(inputs=[input_local, input_global, input_vector], outputs=output)\n","        model.compile(loss=losses.Huber(), optimizer=optimizers.Adam(learning_rate=self.learning_rate, clipnorm=1.0))\n","        return model\n","\n","    def update_target_model(self):\n","        \"\"\"íƒ€ê²Ÿ ëª¨ë¸ì„ ë©”ì¸ ëª¨ë¸ì˜ ìµœì‹  ê°€ì¤‘ì¹˜ë¡œ ë™ê¸°í™”í•©ë‹ˆë‹¤.\"\"\"\n","        self.target_model.set_weights(self.model.get_weights())\n","\n","    def remember(self, state, action, reward, next_state, done, next_valid_actions):\n","        \"\"\"ê²½í—˜ì„ ë²„í¼ì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n","        self.buffer.append((state, action, reward, next_state, done, next_valid_actions))\n","\n","    @tf.function\n","    def _predict(self, local, global_, vector, model_type='main'):\n","        \"\"\"ì»´íŒŒì¼ëœ ì˜ˆì¸¡ í•¨ìˆ˜ (ì¶”ë¡  ì†ë„ ìµœì í™”)\"\"\"\n","        if model_type == 'target':\n","            return self.target_model([local, global_, vector], training=False)\n","        else:\n","            return self.model([local, global_, vector], training=False)\n","\n","    def act(self, state, valid_actions):\n","        \"\"\"í–‰ë™ ì„ íƒ (Epsilon-Greedy + Masking)\"\"\"\n","        # 1. íƒí—˜ (ëœë¤ ì„ íƒ)\n","        if np.random.rand() <= self.epsilon:\n","            valid_indices = np.where(valid_actions)[0]\n","            if len(valid_indices) == 0: return 0\n","            return np.random.choice(valid_indices)\n","\n","        # 2. í™œìš© (ëª¨ë¸ ì¶”ë¡ )\n","        # 3ê°œì˜ ì…ë ¥ì„ ë°°ì¹˜ í¬ê¸° 1ë¡œ ë³€í™˜\n","        local_in = tf.expand_dims(tf.convert_to_tensor(state['local'], dtype=tf.float32), 0)\n","        global_in = tf.expand_dims(tf.convert_to_tensor(state['global'], dtype=tf.float32), 0)\n","        vector_in = tf.expand_dims(tf.convert_to_tensor(state['vector'], dtype=tf.float32), 0)\n","\n","        # ì˜ˆì¸¡ ìˆ˜í–‰\n","        q_values = self._predict(local_in, global_in, vector_in, 'main').numpy()[0]\n","\n","        # ë§ˆìŠ¤í‚¹: ê°ˆ ìˆ˜ ì—†ëŠ” ê³³(-np.inf)ì„ ì œì™¸í•˜ê³  ìµœê³  Qê°’ ì„ íƒ\n","        q_values[~valid_actions] = -np.inf\n","        return np.argmax(q_values)\n","\n","    def replay(self, batch_size):\n","        \"\"\"ê²½í—˜ ë¦¬í”Œë ˆì´ë¥¼ í†µí•œ í•™ìŠµ\"\"\"\n","        if len(self.buffer) < batch_size: return\n","        minibatch = random.sample(self.buffer, batch_size)\n","\n","        # ë°ì´í„° ë¶„ë¦¬ ë° ë°°ì—´í™”\n","        locals_ = np.array([d[0]['local'] for d in minibatch], dtype=np.float32)\n","        globals_ = np.array([d[0]['global'] for d in minibatch], dtype=np.float32)\n","        vectors = np.array([d[0]['vector'] for d in minibatch], dtype=np.float32)\n","        # ... (ë‚˜ë¨¸ì§€ ë°ì´í„° ë¶„ë¦¬)\n","        actions = np.array([d[1] for d in minibatch])\n","        rewards = np.array([d[2] for d in minibatch], dtype=np.float32)\n","        next_locals = np.array([d[3]['local'] for d in minibatch], dtype=np.float32)\n","        next_globals = np.array([d[3]['global'] for d in minibatch], dtype=np.float32)\n","        next_vectors = np.array([d[3]['vector'] for d in minibatch], dtype=np.float32)\n","        dones = np.array([d[4] for d in minibatch], dtype=np.float32)\n","        next_valids = np.array([d[5] for d in minibatch], dtype=bool)\n","\n","        # Double DQN ì •ë‹µì§€ ê³„ì‚°\n","        next_q_target = self._predict(next_locals, next_globals, next_vectors, 'target').numpy()\n","        next_q_main = self._predict(next_locals, next_globals, next_vectors, 'main').numpy()\n","\n","        # Bellman Equation ì ìš©\n","        next_q_main[~next_valids] = -np.inf\n","        best_actions = np.argmax(next_q_main, axis=1)\n","\n","        row_indices = np.arange(batch_size)\n","        next_q_values = next_q_target[row_indices, best_actions]\n","        targets = rewards + self.gamma * next_q_values * (1 - dones)\n","\n","        # ëª¨ë¸ í•™ìŠµ\n","        target_f = self._predict(locals_, globals_, vectors, 'main').numpy()\n","        target_f[row_indices, actions] = targets\n","\n","        self.model.train_on_batch([locals_, globals_, vectors], target_f)\n","\n","    def reheat_epsilon(self, target_epsilon=0.6, force=False):\n","        \"\"\"ì—¡ì‹¤ë¡  ì¬ê°€ì—´ (ìŠ¬ëŸ¼í”„ íƒˆì¶œìš©)\"\"\"\n","        if force or (self.epsilon < target_epsilon):\n","            print(f\"   >>> ğŸ”¥ [ì¬ê°€ì—´] Epsilon: {self.epsilon:.2f} -> {target_epsilon:.2f}\")\n","            self.epsilon = target_epsilon"],"metadata":{"id":"Cf3kvsEjmAvM","executionInfo":{"status":"ok","timestamp":1765098213851,"user_tz":-540,"elapsed":7,"user":{"displayName":"Rai-kyong Jeong","userId":"10124706338105457970"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# [ìˆ˜ì •ëœ] ì„±ëŠ¥ ê²€ì¦ ì‹¤í–‰ ë¡œì§\n","# =========================================================\n","if __name__ == \"__main__\":\n","    # 1. ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ)\n","    GDRIVE_BASE_PATH = '/content/drive/MyDrive/Colab Notebooks/reinforcement learning/Final_Model_4to8'\n","\n","    # ì²´í¬í¬ì¸íŠ¸ ëª¨ë¸ì´ ë” ìµœì‹ ì¼ í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ ìš°ì„  ë¡œë“œ\n","    # MODEL_PATH = os.path.join(GDRIVE_BASE_PATH, \"zip_checkpoint.keras\")\n","    # ë§Œì•½ ì¡¸ì—… ëª¨ë¸ì„ ì“°ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ\n","    MODEL_PATH = os.path.join(GDRIVE_BASE_PATH, \"zip_universal_model.keras\")\n","\n","    print(f\"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {MODEL_PATH}\")\n","\n","    if not os.path.exists(MODEL_PATH):\n","        print(\"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n","        agent_model = None\n","    else:\n","        try:\n","            # ì»¤ìŠ¤í…€ ê°ì²´ ëª…ì‹œ í•„ìˆ˜\n","            agent_model = tf.keras.models.load_model(\n","                MODEL_PATH,\n","                custom_objects={'DuelingMergeLayer': DuelingMergeLayer},\n","                compile=False\n","            )\n","            print(\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n","        except Exception as e:\n","            print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n","            agent_model = None\n","\n","    if agent_model:\n","        # í…ŒìŠ¤íŠ¸ ë²”ìœ„\n","        test_sizes = list(range(4, 13)) # 4x4 ~ 12x12\n","        EPISODES_PER_SIZE = 100\n","\n","        # í…ŒìŠ¤íŠ¸ìš© í™˜ê²½ (í•™ìŠµ ë•Œ ì¼ë˜ ZipGeneralEnv í´ë˜ìŠ¤ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n","        test_env = ZipGeneralEnv(max_grid_size=12, render_mode=None)\n","\n","        print(\"\\nğŸ§ª [ì„±ëŠ¥ ê²€ì¦ ì‹œì‘] 4x4 ~ 12x12 (Epsilon=0.0, Valid Masking ON)\")\n","        print(\"-\" * 65)\n","        print(f\"{'Grid Size':<10} | {'Success Rate':<15} | {'Avg Score':<15} | {'Status'}\")\n","        print(\"-\" * 65)\n","\n","        for size in test_sizes:\n","            test_env.set_curriculum_level(size) # í•´ë‹¹ í¬ê¸° ê³ ì •\n","            success_count = 0\n","            scores = []\n","\n","            for ep in range(EPISODES_PER_SIZE):\n","                # 1. ì´ˆê¸°í™” ë° ì²« ë²ˆì§¸ Valid Actions íšë“\n","                obs, info = test_env.reset()\n","                valid_actions = info['valid_actions'] # â­ï¸ [í•µì‹¬] ë§ˆìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°\n","\n","                done = False\n","                total_reward = 0\n","\n","                while not done:\n","                    # 2. ëª¨ë¸ ì˜ˆì¸¡ì„ ìœ„í•œ ì°¨ì› í™•ì¥\n","                    local_in = tf.expand_dims(obs['local'], 0)\n","                    global_in = tf.expand_dims(obs['global'], 0)\n","                    vector_in = tf.expand_dims(obs['vector'], 0)\n","\n","                    # 3. Qê°’ ì˜ˆì¸¡\n","                    q_values = agent_model([local_in, global_in, vector_in], training=False).numpy()[0]\n","\n","                    # 4. â­ï¸ [í•µì‹¬] ë§ˆìŠ¤í‚¹ ì ìš© (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì¡°ê±´)\n","                    # ê°ˆ ìˆ˜ ì—†ëŠ” ê³³(valid=0)ì€ -ë¬´í•œëŒ€ ì ìˆ˜ë¡œ ë§Œë“¤ì–´ ì„ íƒ ë¶ˆê°€í•˜ê²Œ í•¨\n","                    q_values[valid_actions == 0] = -1e9\n","\n","                    # 5. ìµœì  í–‰ë™ ì„ íƒ\n","                    action = np.argmax(q_values)\n","\n","                    # 6. í™˜ê²½ ì§„í–‰\n","                    obs, reward, terminated, truncated, info = test_env.step(action)\n","\n","                    # â­ï¸ ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•œ ë§ˆìŠ¤í¬ ê°±ì‹ \n","                    valid_actions = info['valid_actions']\n","\n","                    done = terminated or truncated\n","                    total_reward += reward\n","\n","                scores.append(total_reward)\n","\n","                # ì„±ê³µ ê¸°ì¤€ (ì­íŒŸ ì ìˆ˜ ê·¼ì²˜)\n","                target_score = 500.0 + (size * size)\n","                if total_reward >= target_score * 0.9:\n","                    success_count += 1\n","\n","            success_rate = (success_count / EPISODES_PER_SIZE) * 100\n","            avg_score = np.mean(scores)\n","\n","            status = \"ğŸŸ¢ Great\" if success_rate >= 90 else \"ğŸŸ¡ Good\" if success_rate >= 50 else \"ğŸ”´ Fail\"\n","            print(f\"{size}x{size:<8} | {success_rate:6.1f}%        | {avg_score:8.1f}        | {status}\")\n","\n","        print(\"-\" * 65)\n","        print(\"âœ… ê²€ì¦ ì™„ë£Œ.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPliGLTHmDvw","executionInfo":{"status":"ok","timestamp":1765099047043,"user_tz":-540,"elapsed":830251,"user":{"displayName":"Rai-kyong Jeong","userId":"10124706338105457970"}},"outputId":"dfe87232-dd1a-403c-9536-b07dd4704f27"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: /content/drive/MyDrive/Colab Notebooks/reinforcement learning/Final_Model_4to8/zip_universal_model.keras\n","âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\n","\n","ğŸ§ª [ì„±ëŠ¥ ê²€ì¦ ì‹œì‘] 4x4 ~ 12x12 (Epsilon=0.0, Valid Masking ON)\n","-----------------------------------------------------------------\n","Grid Size  | Success Rate    | Avg Score       | Status\n","-----------------------------------------------------------------\n","4x4        |   99.0%        |    551.0        | ğŸŸ¢ Great\n","5x5        |   97.0%        |    557.3        | ğŸŸ¢ Great\n","6x6        |   87.0%        |    537.1        | ğŸŸ¡ Good\n","7x7        |   84.0%        |    549.8        | ğŸŸ¡ Good\n","8x8        |   84.0%        |    588.7        | ğŸŸ¡ Good\n","9x9        |   54.0%        |    417.1        | ğŸŸ¡ Good\n","10x10       |   26.0%        |    301.3        | ğŸ”´ Fail\n","11x11       |   11.0%        |    255.3        | ğŸ”´ Fail\n","12x12       |   25.0%        |    316.6        | ğŸ”´ Fail\n","-----------------------------------------------------------------\n","âœ… ê²€ì¦ ì™„ë£Œ.\n"]}]}]}